{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Brief Introduction to Linear Regression\n",
    "---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression attempts to model the relationship between two variables by fitting a linear equation to observed data. One variable is considered to be an explanatory variable, and the other is considered to be a dependent variable. For example, a modeler might want to relate the weights of individuals to their heights using a linear regression model.\n",
    "\n",
    "Before attempting to fit a linear model to observed data, a modeler should first determine whether or not there is a relationship between the variables of interest. This does not necessarily imply that one variable causes the other (for example, higher SAT scores do not cause higher college grades), but that there is some significant association between the two variables.\n",
    "\n",
    "A linear regression line has an equation of the form Y = a + bX, where X is the explanatory variable and Y is the dependent variable. The slope of the line is b, and a is the intercept (the value of y when x = 0).\n",
    "[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/3/3a/Linear_regression.svg\">\n",
    "\n",
    "Example of simple linear regression, which has one independent variable [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least-Squares Regression\n",
    "The most common method for fitting a regression line is the method of least-squares. This method calculates the best-fitting line for the observed data by minimizing the sum of the squares of the vertical deviations from each data point to the line (if a point lies on the fitted line exactly, then its vertical deviation is 0). Because the deviations are first squared, then summed, there are no cancellations between positive and negative values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.stat.yale.edu/Courses/1997-98/101/lsline.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers and Influential Observations\n",
    "After a regression line has been computed for a group of data, a point which lies far from the line (and thus has a large residual value) is known as an outlier. Such points may represent erroneous data, or may indicate a poorly fitting regression line. If a point lies far from the other data in the horizontal direction, it is known as an influential observation. The reason for this distinction is that these points have may have a significant impact on the slope of the regression line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.stat.yale.edu/Courses/1997-98/101/lsline2.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residuals\n",
    "Once a regression model has been fit to a group of data, examination of the residuals (the deviations from the fitted line to the observed values) allows the modeler to investigate the validity of his or her assumption that a linear relationship exists. Plotting the residuals on the y-axis against the explanatory variable on the x-axis reveals any possible non-linear relationship among the variables, or might alert the modeler to investigate lurking variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.stat.yale.edu/Courses/1997-98/101/lsresid.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Read More: Linear Regression](http://www.stat.yale.edu/Courses/1997-98/101/linreg.htm \"Linear Regression : Yale\")\n",
    "\n",
    "[Read More: Linear Regression Course](https://onlinecourses.science.psu.edu/stat501/node/250 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 : Implementing Linear Regression\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the necessary libraries to get the work started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahil\\Anaconda3\\envs\\py35\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np                  #It provides some advance math functionalities to python\n",
    "import pandas as pd                 #to load the data file as a Pandas data frame and analyze the data\n",
    "from scipy import stats             #SciPy contains modules for optimization, linear algebra, integration, interpolation, special functions, FFT, signal and image processing, ODE solvers and other tasks common in science and engineering.\n",
    "import seaborn as sns               #Seaborn is a Python visualization library based on matplotlib. It provides a high-level interface for drawing attractive statistical graphics.\n",
    "import warnings\n",
    "import random\n",
    "from sklearn import cross_validation                                                        # Scikit-learn (formerly scikits.learn) is a free software machine learning library for the Python programming language.\n",
    "from sklearn.cross_validation import KFold, cross_val_score, train_test_split               # It features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN,\n",
    "from sklearn import metrics                                                                 # and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy.\n",
    "from datetime import datetime       #The datetime module supplies classes for manipulating dates and times in both simple and complex ways.\n",
    "random.seed(datetime.now())\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20, 10) #Defining size of plots\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing, cross_validation, svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.metrics import roc_curve # ROC Curves\n",
    "from sklearn.metrics import auc # Calculating AUC(Area under the curve) for ROC's(Reciever Operating Characteristics)!\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the data in CSV (Comma Seperated Value) Format, after data scrapping and cleaning. To read more on it : [Data Retrival](https://cocalc.com/projects/555ac5a9-25b4-4679-831c-1287ecda54c7/files/Blog/Blog.ipynb?session=default) and [Data Cleaning](https://github.com/MandyYang86/Ride-Optimization/blob/master/Data%20Clean%20Part/DataClean_OneMonth_Uber_Pool.ipynb).\n",
    "\n",
    "So we need to import it in our pandas dataframe for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"uber_lyft_March.csv\")\n",
    "ds = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at how our dataset looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>uber_distance</th>\n",
       "      <th>uber_duration</th>\n",
       "      <th>uber_estimate</th>\n",
       "      <th>uber_high_estimate</th>\n",
       "      <th>uber_low_estimate</th>\n",
       "      <th>main_temp</th>\n",
       "      <th>weather</th>\n",
       "      <th>uber_price_per_second</th>\n",
       "      <th>lyft_distance</th>\n",
       "      <th>lyft_duration</th>\n",
       "      <th>lyft_max_estimate</th>\n",
       "      <th>lyft_min_estimate</th>\n",
       "      <th>lyft_estimate</th>\n",
       "      <th>lyft_price_per_second</th>\n",
       "      <th>average_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3/1/18 0:00</td>\n",
       "      <td>1.73</td>\n",
       "      <td>360</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>46.69</td>\n",
       "      <td>Rain</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>1.76</td>\n",
       "      <td>414</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.008786</td>\n",
       "      <td>387.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3/1/18 0:01</td>\n",
       "      <td>1.90</td>\n",
       "      <td>480</td>\n",
       "      <td>5.5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>46.69</td>\n",
       "      <td>Rain</td>\n",
       "      <td>0.010816</td>\n",
       "      <td>1.79</td>\n",
       "      <td>537</td>\n",
       "      <td>3.53</td>\n",
       "      <td>3.53</td>\n",
       "      <td>3.53</td>\n",
       "      <td>0.006942</td>\n",
       "      <td>508.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/1/18 0:02</td>\n",
       "      <td>2.26</td>\n",
       "      <td>420</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>46.56</td>\n",
       "      <td>Rain</td>\n",
       "      <td>0.015436</td>\n",
       "      <td>2.20</td>\n",
       "      <td>487</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.008490</td>\n",
       "      <td>453.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3/1/18 0:03</td>\n",
       "      <td>1.63</td>\n",
       "      <td>360</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>46.56</td>\n",
       "      <td>Rain</td>\n",
       "      <td>0.018029</td>\n",
       "      <td>1.70</td>\n",
       "      <td>472</td>\n",
       "      <td>3.46</td>\n",
       "      <td>3.46</td>\n",
       "      <td>3.46</td>\n",
       "      <td>0.008317</td>\n",
       "      <td>416.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3/1/18 0:04</td>\n",
       "      <td>2.17</td>\n",
       "      <td>480</td>\n",
       "      <td>9.5</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>46.56</td>\n",
       "      <td>Rain</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>2.21</td>\n",
       "      <td>553</td>\n",
       "      <td>3.47</td>\n",
       "      <td>3.47</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.006718</td>\n",
       "      <td>516.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     date_time  uber_distance  uber_duration  uber_estimate  \\\n",
       "0  3/1/18 0:00           1.73            360            7.5   \n",
       "1  3/1/18 0:01           1.90            480            5.5   \n",
       "2  3/1/18 0:02           2.26            420            7.0   \n",
       "3  3/1/18 0:03           1.63            360            7.5   \n",
       "4  3/1/18 0:04           2.17            480            9.5   \n",
       "\n",
       "   uber_high_estimate  uber_low_estimate  main_temp weather  \\\n",
       "0                   9                  6      46.69    Rain   \n",
       "1                   7                  4      46.69    Rain   \n",
       "2                   9                  5      46.56    Rain   \n",
       "3                   9                  6      46.56    Rain   \n",
       "4                  11                  8      46.56    Rain   \n",
       "\n",
       "   uber_price_per_second  lyft_distance  lyft_duration  lyft_max_estimate  \\\n",
       "0               0.019380           1.76            414               3.40   \n",
       "1               0.010816           1.79            537               3.53   \n",
       "2               0.015436           2.20            487               3.85   \n",
       "3               0.018029           1.70            472               3.46   \n",
       "4               0.018393           2.21            553               3.47   \n",
       "\n",
       "   lyft_min_estimate  lyft_estimate  lyft_price_per_second  average_duration  \n",
       "0               3.40           3.40               0.008786             387.0  \n",
       "1               3.53           3.53               0.006942             508.5  \n",
       "2               3.85           3.85               0.008490             453.5  \n",
       "3               3.46           3.46               0.008317             416.0  \n",
       "4               3.47           3.47               0.006718             516.5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we are only using the essential columns required, which will be the features that will help us predict the outcome. Here the date time will help us in indexing the dataframe for ease of access, whereas, other columns will be predictors, that will allow us to forecast the future using the historical data we have until now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date_time', 'uber_distance', 'uber_duration', 'uber_estimate',\n",
       "       'uber_high_estimate', 'uber_low_estimate', 'main_temp', 'weather',\n",
       "       'uber_price_per_second', 'lyft_distance', 'lyft_duration',\n",
       "       'lyft_max_estimate', 'lyft_min_estimate', 'lyft_estimate',\n",
       "       'lyft_price_per_second', 'average_duration'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to check whether all the columns have proper data type we need for linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_time                 object\n",
       "uber_distance            float64\n",
       "uber_duration              int64\n",
       "uber_estimate            float64\n",
       "uber_high_estimate         int64\n",
       "uber_low_estimate          int64\n",
       "main_temp                float64\n",
       "weather                   object\n",
       "uber_price_per_second    float64\n",
       "lyft_distance            float64\n",
       "lyft_duration              int64\n",
       "lyft_max_estimate        float64\n",
       "lyft_min_estimate        float64\n",
       "lyft_estimate            float64\n",
       "lyft_price_per_second    float64\n",
       "average_duration         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find out that the weather column needs to converted into some kind of a numerical format as linear regression does not process categorical data. So we convert unique weather names and  assign it a numerical label, as a work around for using linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['weather']] = df[\"weather\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weather_label'] = df[\"weather\"].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we can see that which label represents which weather condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weather\n",
       "Clear      [0]\n",
       "Clouds     [1]\n",
       "Drizzle    [2]\n",
       "Fog        [3]\n",
       "Haze       [4]\n",
       "Mist       [5]\n",
       "Rain       [6]\n",
       "Snow       [7]\n",
       "Name: weather_label, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('weather')['weather_label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop unnecessary columns which will not be used in any further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['uber_high_estimate', 'uber_low_estimate', 'lyft_max_estimate', 'lyft_min_estimate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use data_time as our index now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('date_time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uber_distance</th>\n",
       "      <th>uber_duration</th>\n",
       "      <th>uber_estimate</th>\n",
       "      <th>main_temp</th>\n",
       "      <th>weather</th>\n",
       "      <th>uber_price_per_second</th>\n",
       "      <th>lyft_distance</th>\n",
       "      <th>lyft_duration</th>\n",
       "      <th>lyft_estimate</th>\n",
       "      <th>lyft_price_per_second</th>\n",
       "      <th>average_duration</th>\n",
       "      <th>weather_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3/1/18 0:00</th>\n",
       "      <td>1.73</td>\n",
       "      <td>360</td>\n",
       "      <td>7.5</td>\n",
       "      <td>46.69</td>\n",
       "      <td>Rain</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>1.76</td>\n",
       "      <td>414</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.008786</td>\n",
       "      <td>387.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/1/18 0:01</th>\n",
       "      <td>1.90</td>\n",
       "      <td>480</td>\n",
       "      <td>5.5</td>\n",
       "      <td>46.69</td>\n",
       "      <td>Rain</td>\n",
       "      <td>0.010816</td>\n",
       "      <td>1.79</td>\n",
       "      <td>537</td>\n",
       "      <td>3.53</td>\n",
       "      <td>0.006942</td>\n",
       "      <td>508.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/1/18 0:02</th>\n",
       "      <td>2.26</td>\n",
       "      <td>420</td>\n",
       "      <td>7.0</td>\n",
       "      <td>46.56</td>\n",
       "      <td>Rain</td>\n",
       "      <td>0.015436</td>\n",
       "      <td>2.20</td>\n",
       "      <td>487</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.008490</td>\n",
       "      <td>453.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/1/18 0:03</th>\n",
       "      <td>1.63</td>\n",
       "      <td>360</td>\n",
       "      <td>7.5</td>\n",
       "      <td>46.56</td>\n",
       "      <td>Rain</td>\n",
       "      <td>0.018029</td>\n",
       "      <td>1.70</td>\n",
       "      <td>472</td>\n",
       "      <td>3.46</td>\n",
       "      <td>0.008317</td>\n",
       "      <td>416.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/1/18 0:04</th>\n",
       "      <td>2.17</td>\n",
       "      <td>480</td>\n",
       "      <td>9.5</td>\n",
       "      <td>46.56</td>\n",
       "      <td>Rain</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>2.21</td>\n",
       "      <td>553</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.006718</td>\n",
       "      <td>516.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             uber_distance  uber_duration  uber_estimate  main_temp weather  \\\n",
       "date_time                                                                     \n",
       "3/1/18 0:00           1.73            360            7.5      46.69    Rain   \n",
       "3/1/18 0:01           1.90            480            5.5      46.69    Rain   \n",
       "3/1/18 0:02           2.26            420            7.0      46.56    Rain   \n",
       "3/1/18 0:03           1.63            360            7.5      46.56    Rain   \n",
       "3/1/18 0:04           2.17            480            9.5      46.56    Rain   \n",
       "\n",
       "             uber_price_per_second  lyft_distance  lyft_duration  \\\n",
       "date_time                                                          \n",
       "3/1/18 0:00               0.019380           1.76            414   \n",
       "3/1/18 0:01               0.010816           1.79            537   \n",
       "3/1/18 0:02               0.015436           2.20            487   \n",
       "3/1/18 0:03               0.018029           1.70            472   \n",
       "3/1/18 0:04               0.018393           2.21            553   \n",
       "\n",
       "             lyft_estimate  lyft_price_per_second  average_duration  \\\n",
       "date_time                                                             \n",
       "3/1/18 0:00           3.40               0.008786             387.0   \n",
       "3/1/18 0:01           3.53               0.006942             508.5   \n",
       "3/1/18 0:02           3.85               0.008490             453.5   \n",
       "3/1/18 0:03           3.46               0.008317             416.0   \n",
       "3/1/18 0:04           3.47               0.006718             516.5   \n",
       "\n",
       "             weather_label  \n",
       "date_time                   \n",
       "3/1/18 0:00              6  \n",
       "3/1/18 0:01              6  \n",
       "3/1/18 0:02              6  \n",
       "3/1/18 0:03              6  \n",
       "3/1/18 0:04              6  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the features and what is the label? We're trying to predict the price per second, so is that the label? If so, what are the featuers? When it comes to forecasting out the price, our label, the thing we're hoping to predict, is actually the future price. As such, our features are actually: uber_distance, uber_duration, lyft_price_per_second, average_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_col = 'uber_price_per_second'\n",
    "forecast_col_1 = 'lyft_price_per_second'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df[forecast_col]\n",
    "df['label_1'] = df[forecast_col_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, you want your features in machine learning to be in a range of -1 to 1. This may do nothing, but it usually speeds up processing and can also help with accuracy. Because this range is so popularly used, it is included in the preprocessing module of Scikit-Learn. To utilize this, you can apply preprocessing.scale to your X variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df[['uber_distance','uber_duration','lyft_price_per_second','average_duration','weather_label']])\n",
    "X = preprocessing.scale(X)\n",
    "\n",
    "X1 = np.array(df[['lyft_distance','lyft_duration','uber_price_per_second','average_duration','weather_label']])\n",
    "X1 = preprocessing.scale(X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the training and testing. The way this works is you take, for example, 75% of your data, and use this to train the machine learning classifier. Then you take the remaining 25% of your data, and test the classifier. Since this is your sample data, you should have the features and known labels. Thus, if you test on the last 25% of your data, you can get a sort of accuracy and reliability, often called the confidence score. There are many ways to do this, but, probably the best way is using the build in cross_validation provided, since this also shuffles your data for you. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df['uber_price_per_second'])\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "y1 = np.array(df['lyft_price_per_second'])\n",
    "X1_train, X1_test, y1_train, y1_test = cross_validation.train_test_split(X1, y1, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The return here is the training set of features, testing set of features, training set of labels, and testing set of labels. Now, we're ready to define our classifier. There are many classifiers in general available through Scikit-Learn, and even a few specifically for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46567509338070623\n",
      "0.27785464216072675\n"
     ]
    }
   ],
   "source": [
    "clf = LinearRegression()\n",
    "results = clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "\n",
    "results = clf.fit(X1_train, y1_train)\n",
    "accuracy = clf.score(X1_test, y1_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that analysing the historical data and its features using linear regression doesnt give us favourable results. Lets see how we can analyse the errors to understand this better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44434, 5)\n",
      "(44434,)\n",
      "(33325, 5)\n",
      "(33325,)\n",
      "(11109, 5)\n",
      "(11109,)\n"
     ]
    }
   ],
   "source": [
    "print (X.shape)\n",
    "print (y.shape)\n",
    "print (X_train.shape)\n",
    "print (y_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014779471244987737 [ 0.00170932  0.00055261  0.00190103 -0.00348194  0.00020052]\n"
     ]
    }
   ],
   "source": [
    "# Fit the linear model\n",
    "model = linear_model.LinearRegression()\n",
    "results = model.fit(X_train, y_train)\n",
    "\n",
    "# Print the coefficients\n",
    "print (results.intercept_, results.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start with the errors in prediction of training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_pred = model.predict(X_test) # Predicting the features of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uber_pred</th>\n",
       "      <th>actual</th>\n",
       "      <th>percent_linear_regression_error</th>\n",
       "      <th>baseline_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016814</td>\n",
       "      <td>0.017316</td>\n",
       "      <td>2.898004</td>\n",
       "      <td>14.548791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013113</td>\n",
       "      <td>0.009590</td>\n",
       "      <td>36.729357</td>\n",
       "      <td>54.289710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016005</td>\n",
       "      <td>0.015931</td>\n",
       "      <td>0.460145</td>\n",
       "      <td>7.121967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016263</td>\n",
       "      <td>0.012799</td>\n",
       "      <td>27.065443</td>\n",
       "      <td>15.611906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010821</td>\n",
       "      <td>0.009040</td>\n",
       "      <td>19.693094</td>\n",
       "      <td>63.674769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.014911</td>\n",
       "      <td>0.013052</td>\n",
       "      <td>14.240990</td>\n",
       "      <td>13.365836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.017691</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>7.858594</td>\n",
       "      <td>22.933616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.014153</td>\n",
       "      <td>0.013798</td>\n",
       "      <td>2.575454</td>\n",
       "      <td>7.237467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.014036</td>\n",
       "      <td>0.012452</td>\n",
       "      <td>12.720393</td>\n",
       "      <td>18.829254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.012042</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>43.388628</td>\n",
       "      <td>76.186973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.018081</td>\n",
       "      <td>0.015402</td>\n",
       "      <td>17.400273</td>\n",
       "      <td>3.926842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.014753</td>\n",
       "      <td>0.021525</td>\n",
       "      <td>31.461188</td>\n",
       "      <td>31.258546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.019897</td>\n",
       "      <td>0.016861</td>\n",
       "      <td>18.001891</td>\n",
       "      <td>12.243914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.018904</td>\n",
       "      <td>0.020776</td>\n",
       "      <td>9.008975</td>\n",
       "      <td>28.778329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.014005</td>\n",
       "      <td>0.012683</td>\n",
       "      <td>10.420997</td>\n",
       "      <td>16.666648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.008379</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>10.328212</td>\n",
       "      <td>94.823812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.012731</td>\n",
       "      <td>0.011756</td>\n",
       "      <td>8.291450</td>\n",
       "      <td>25.864816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.018606</td>\n",
       "      <td>0.024159</td>\n",
       "      <td>22.985883</td>\n",
       "      <td>38.752043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.015621</td>\n",
       "      <td>0.014365</td>\n",
       "      <td>8.749428</td>\n",
       "      <td>3.008114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.013531</td>\n",
       "      <td>0.008507</td>\n",
       "      <td>59.050650</td>\n",
       "      <td>73.929026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.014561</td>\n",
       "      <td>0.015886</td>\n",
       "      <td>8.338939</td>\n",
       "      <td>6.854488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.010955</td>\n",
       "      <td>0.009150</td>\n",
       "      <td>19.721378</td>\n",
       "      <td>61.707290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.014310</td>\n",
       "      <td>0.009442</td>\n",
       "      <td>51.555863</td>\n",
       "      <td>56.710991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.015892</td>\n",
       "      <td>0.012948</td>\n",
       "      <td>22.737536</td>\n",
       "      <td>14.276408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.008164</td>\n",
       "      <td>0.007159</td>\n",
       "      <td>14.047226</td>\n",
       "      <td>106.692034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.013424</td>\n",
       "      <td>0.010737</td>\n",
       "      <td>25.019972</td>\n",
       "      <td>37.807029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.020209</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>15.797831</td>\n",
       "      <td>38.346892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.008656</td>\n",
       "      <td>0.008526</td>\n",
       "      <td>1.522467</td>\n",
       "      <td>73.544682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.013419</td>\n",
       "      <td>0.010621</td>\n",
       "      <td>26.345103</td>\n",
       "      <td>39.317053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.017325</td>\n",
       "      <td>0.020681</td>\n",
       "      <td>16.227356</td>\n",
       "      <td>28.453381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.013959</td>\n",
       "      <td>0.013908</td>\n",
       "      <td>0.363084</td>\n",
       "      <td>6.388601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.012508</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>19.978382</td>\n",
       "      <td>41.934939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.018451</td>\n",
       "      <td>0.017839</td>\n",
       "      <td>3.427510</td>\n",
       "      <td>17.056019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.011417</td>\n",
       "      <td>0.011838</td>\n",
       "      <td>3.558575</td>\n",
       "      <td>24.988983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.013775</td>\n",
       "      <td>0.013993</td>\n",
       "      <td>1.557378</td>\n",
       "      <td>5.747412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.015862</td>\n",
       "      <td>0.017615</td>\n",
       "      <td>9.952833</td>\n",
       "      <td>16.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.016409</td>\n",
       "      <td>0.014808</td>\n",
       "      <td>10.814006</td>\n",
       "      <td>0.072640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.011505</td>\n",
       "      <td>0.013413</td>\n",
       "      <td>14.221793</td>\n",
       "      <td>10.317958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.015745</td>\n",
       "      <td>0.016822</td>\n",
       "      <td>6.405124</td>\n",
       "      <td>12.041567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.011877</td>\n",
       "      <td>0.013555</td>\n",
       "      <td>12.378038</td>\n",
       "      <td>9.159628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.007287</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>24.606606</td>\n",
       "      <td>153.024363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.018716</td>\n",
       "      <td>0.016688</td>\n",
       "      <td>12.149860</td>\n",
       "      <td>11.333348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.010808</td>\n",
       "      <td>0.008606</td>\n",
       "      <td>25.593174</td>\n",
       "      <td>71.938186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.015847</td>\n",
       "      <td>0.030172</td>\n",
       "      <td>47.478178</td>\n",
       "      <td>50.959357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.009876</td>\n",
       "      <td>0.007077</td>\n",
       "      <td>39.555051</td>\n",
       "      <td>109.089388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.015211</td>\n",
       "      <td>0.012871</td>\n",
       "      <td>18.180694</td>\n",
       "      <td>14.959334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.016749</td>\n",
       "      <td>0.018027</td>\n",
       "      <td>7.086393</td>\n",
       "      <td>17.916997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.020805</td>\n",
       "      <td>0.016886</td>\n",
       "      <td>23.208879</td>\n",
       "      <td>12.370381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.015236</td>\n",
       "      <td>0.016441</td>\n",
       "      <td>7.328915</td>\n",
       "      <td>10.000971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.017409</td>\n",
       "      <td>0.016190</td>\n",
       "      <td>7.525134</td>\n",
       "      <td>8.608334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    uber_pred    actual  percent_linear_regression_error  baseline_error\n",
       "0    0.016814  0.017316                         2.898004       14.548791\n",
       "1    0.013113  0.009590                        36.729357       54.289710\n",
       "2    0.016005  0.015931                         0.460145        7.121967\n",
       "3    0.016263  0.012799                        27.065443       15.611906\n",
       "4    0.010821  0.009040                        19.693094       63.674769\n",
       "5    0.014911  0.013052                        14.240990       13.365836\n",
       "6    0.017691  0.019200                         7.858594       22.933616\n",
       "7    0.014153  0.013798                         2.575454        7.237467\n",
       "8    0.014036  0.012452                        12.720393       18.829254\n",
       "9    0.012042  0.008398                        43.388628       76.186973\n",
       "10   0.018081  0.015402                        17.400273        3.926842\n",
       "11   0.014753  0.021525                        31.461188       31.258546\n",
       "12   0.019897  0.016861                        18.001891       12.243914\n",
       "13   0.018904  0.020776                         9.008975       28.778329\n",
       "14   0.014005  0.012683                        10.420997       16.666648\n",
       "15   0.008379  0.007595                        10.328212       94.823812\n",
       "16   0.012731  0.011756                         8.291450       25.864816\n",
       "17   0.018606  0.024159                        22.985883       38.752043\n",
       "18   0.015621  0.014365                         8.749428        3.008114\n",
       "19   0.013531  0.008507                        59.050650       73.929026\n",
       "20   0.014561  0.015886                         8.338939        6.854488\n",
       "21   0.010955  0.009150                        19.721378       61.707290\n",
       "22   0.014310  0.009442                        51.555863       56.710991\n",
       "23   0.015892  0.012948                        22.737536       14.276408\n",
       "24   0.008164  0.007159                        14.047226      106.692034\n",
       "25   0.013424  0.010737                        25.019972       37.807029\n",
       "26   0.020209  0.024000                        15.797831       38.346892\n",
       "27   0.008656  0.008526                         1.522467       73.544682\n",
       "28   0.013419  0.010621                        26.345103       39.317053\n",
       "29   0.017325  0.020681                        16.227356       28.453381\n",
       "30   0.013959  0.013908                         0.363084        6.388601\n",
       "31   0.012508  0.010425                        19.978382       41.934939\n",
       "32   0.018451  0.017839                         3.427510       17.056019\n",
       "33   0.011417  0.011838                         3.558575       24.988983\n",
       "34   0.013775  0.013993                         1.557378        5.747412\n",
       "35   0.015862  0.017615                         9.952833       16.000012\n",
       "36   0.016409  0.014808                        10.814006        0.072640\n",
       "37   0.011505  0.013413                        14.221793       10.317958\n",
       "38   0.015745  0.016822                         6.405124       12.041567\n",
       "39   0.011877  0.013555                        12.378038        9.159628\n",
       "40   0.007287  0.005848                        24.606606      153.024363\n",
       "41   0.018716  0.016688                        12.149860       11.333348\n",
       "42   0.010808  0.008606                        25.593174       71.938186\n",
       "43   0.015847  0.030172                        47.478178       50.959357\n",
       "44   0.009876  0.007077                        39.555051      109.089388\n",
       "45   0.015211  0.012871                        18.180694       14.959334\n",
       "46   0.016749  0.018027                         7.086393       17.916997\n",
       "47   0.020805  0.016886                        23.208879       12.370381\n",
       "48   0.015236  0.016441                         7.328915       10.000971\n",
       "49   0.017409  0.016190                         7.525134        8.608334"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame()                     # Create a blank dataframe\n",
    "output['uber_pred'] = uber_pred             # Add a column of predicted value of uber prices\n",
    "output['actual'] = y_test                   # Add a column of the actual value of uber prices, we put them side by side for easy comparison\n",
    "output['percent_linear_regression_error'] = abs(output['actual']-output['uber_pred'])*100/output['actual']              # Finding the precentage error between the predicted values and the actual values\n",
    "train_mean = np.mean(y_train)                #Baseline prediction - is the average value of dependent variable. So we are taking a mean baseline apporach.\n",
    "output['baseline_error'] = abs(output['actual']-train_mean)*100/output['actual']\n",
    "output.head(n=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the regression error is much less compared to the baseline error, but still significant enough to decrease the accuracy of our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Baseline Error:  27.554613385672802\n",
      "Mean Regression Error:  18.707245355226576\n"
     ]
    }
   ],
   "source": [
    "print ('Mean Baseline Error: ', output['baseline_error'].mean())\n",
    "print ('Mean Regression Error: ', output['percent_linear_regression_error'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Random Forest Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random forest is a meta estimator that fits a number of classifying decision trees on various sub-samples of the dataset and use averaging to improve the predictive accuracy and control over-fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest solves the instability problem using bagging. We simply estimate the desired Regression Tree on many bootstrap samples (re-sample the data many times with replacement and re-estimate the model) and make the final prediction as the average of the predictions across the trees.\n",
    "\n",
    "There is one small (but important) detail to add. The Random Forest adds a new source of instability to the individual trees. Every time we calculate a new optimal variable-observation point to split the tree, we do not use all variables. Instead, we randomly select 2/3 of the variables. This will make the individual trees even more unstable, but as I mentioned here, bagging benefits from instability.\n",
    "\n",
    "[Read More: Random Forest Regression](https://www.r-bloggers.com/how-random-forests-improve-simple-regression-trees/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators = 1000, random_state = 18, max_depth = 5) # We chose 1000 trees in the forest, 18 is the seed for the forest and we chose the maximumn depth of the trees to be 5.\n",
    "ouput_random_forest = model.fit(X_train, y_train)\n",
    "random_forest_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uber_pred</th>\n",
       "      <th>actual</th>\n",
       "      <th>percent_linear_regression_error</th>\n",
       "      <th>baseline_error</th>\n",
       "      <th>uber_pred_rf</th>\n",
       "      <th>percent_random_forest_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016814</td>\n",
       "      <td>0.017316</td>\n",
       "      <td>2.898004</td>\n",
       "      <td>14.548791</td>\n",
       "      <td>0.015533</td>\n",
       "      <td>10.299190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013113</td>\n",
       "      <td>0.009590</td>\n",
       "      <td>36.729357</td>\n",
       "      <td>54.289710</td>\n",
       "      <td>0.013129</td>\n",
       "      <td>36.898197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016005</td>\n",
       "      <td>0.015931</td>\n",
       "      <td>0.460145</td>\n",
       "      <td>7.121967</td>\n",
       "      <td>0.013178</td>\n",
       "      <td>17.284054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016263</td>\n",
       "      <td>0.012799</td>\n",
       "      <td>27.065443</td>\n",
       "      <td>15.611906</td>\n",
       "      <td>0.014937</td>\n",
       "      <td>16.706879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010821</td>\n",
       "      <td>0.009040</td>\n",
       "      <td>19.693094</td>\n",
       "      <td>63.674769</td>\n",
       "      <td>0.012361</td>\n",
       "      <td>36.731897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.014911</td>\n",
       "      <td>0.013052</td>\n",
       "      <td>14.240990</td>\n",
       "      <td>13.365836</td>\n",
       "      <td>0.014569</td>\n",
       "      <td>11.621041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.017691</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>7.858594</td>\n",
       "      <td>22.933616</td>\n",
       "      <td>0.017877</td>\n",
       "      <td>6.892631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.014153</td>\n",
       "      <td>0.013798</td>\n",
       "      <td>2.575454</td>\n",
       "      <td>7.237467</td>\n",
       "      <td>0.012870</td>\n",
       "      <td>6.729413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.014036</td>\n",
       "      <td>0.012452</td>\n",
       "      <td>12.720393</td>\n",
       "      <td>18.829254</td>\n",
       "      <td>0.014705</td>\n",
       "      <td>18.095251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.012042</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>43.388628</td>\n",
       "      <td>76.186973</td>\n",
       "      <td>0.010619</td>\n",
       "      <td>26.438498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.018081</td>\n",
       "      <td>0.015402</td>\n",
       "      <td>17.400273</td>\n",
       "      <td>3.926842</td>\n",
       "      <td>0.018293</td>\n",
       "      <td>18.770946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.014753</td>\n",
       "      <td>0.021525</td>\n",
       "      <td>31.461188</td>\n",
       "      <td>31.258546</td>\n",
       "      <td>0.014923</td>\n",
       "      <td>30.670501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.019897</td>\n",
       "      <td>0.016861</td>\n",
       "      <td>18.001891</td>\n",
       "      <td>12.243914</td>\n",
       "      <td>0.021997</td>\n",
       "      <td>30.461449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.018904</td>\n",
       "      <td>0.020776</td>\n",
       "      <td>9.008975</td>\n",
       "      <td>28.778329</td>\n",
       "      <td>0.018208</td>\n",
       "      <td>12.361087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.014005</td>\n",
       "      <td>0.012683</td>\n",
       "      <td>10.420997</td>\n",
       "      <td>16.666648</td>\n",
       "      <td>0.013812</td>\n",
       "      <td>8.898630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.008379</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>10.328212</td>\n",
       "      <td>94.823812</td>\n",
       "      <td>0.010696</td>\n",
       "      <td>40.832254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.012731</td>\n",
       "      <td>0.011756</td>\n",
       "      <td>8.291450</td>\n",
       "      <td>25.864816</td>\n",
       "      <td>0.011988</td>\n",
       "      <td>1.973511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.018606</td>\n",
       "      <td>0.024159</td>\n",
       "      <td>22.985883</td>\n",
       "      <td>38.752043</td>\n",
       "      <td>0.017681</td>\n",
       "      <td>26.812377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.015621</td>\n",
       "      <td>0.014365</td>\n",
       "      <td>8.749428</td>\n",
       "      <td>3.008114</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>8.775644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.013531</td>\n",
       "      <td>0.008507</td>\n",
       "      <td>59.050650</td>\n",
       "      <td>73.929026</td>\n",
       "      <td>0.013535</td>\n",
       "      <td>59.098033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.014561</td>\n",
       "      <td>0.015886</td>\n",
       "      <td>8.338939</td>\n",
       "      <td>6.854488</td>\n",
       "      <td>0.012490</td>\n",
       "      <td>21.378187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.010955</td>\n",
       "      <td>0.009150</td>\n",
       "      <td>19.721378</td>\n",
       "      <td>61.707290</td>\n",
       "      <td>0.011826</td>\n",
       "      <td>29.241217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.014310</td>\n",
       "      <td>0.009442</td>\n",
       "      <td>51.555863</td>\n",
       "      <td>56.710991</td>\n",
       "      <td>0.013178</td>\n",
       "      <td>39.569094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.015892</td>\n",
       "      <td>0.012948</td>\n",
       "      <td>22.737536</td>\n",
       "      <td>14.276408</td>\n",
       "      <td>0.014834</td>\n",
       "      <td>14.567736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.008164</td>\n",
       "      <td>0.007159</td>\n",
       "      <td>14.047226</td>\n",
       "      <td>106.692034</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>47.245069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.013424</td>\n",
       "      <td>0.010737</td>\n",
       "      <td>25.019972</td>\n",
       "      <td>37.807029</td>\n",
       "      <td>0.012305</td>\n",
       "      <td>14.600571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.020209</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>15.797831</td>\n",
       "      <td>38.346892</td>\n",
       "      <td>0.019291</td>\n",
       "      <td>19.621025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.008656</td>\n",
       "      <td>0.008526</td>\n",
       "      <td>1.522467</td>\n",
       "      <td>73.544682</td>\n",
       "      <td>0.010181</td>\n",
       "      <td>19.402908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.013419</td>\n",
       "      <td>0.010621</td>\n",
       "      <td>26.345103</td>\n",
       "      <td>39.317053</td>\n",
       "      <td>0.012226</td>\n",
       "      <td>15.109210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.017325</td>\n",
       "      <td>0.020681</td>\n",
       "      <td>16.227356</td>\n",
       "      <td>28.453381</td>\n",
       "      <td>0.016755</td>\n",
       "      <td>18.982341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.013959</td>\n",
       "      <td>0.013908</td>\n",
       "      <td>0.363084</td>\n",
       "      <td>6.388601</td>\n",
       "      <td>0.013040</td>\n",
       "      <td>6.244065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.012508</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>19.978382</td>\n",
       "      <td>41.934939</td>\n",
       "      <td>0.011853</td>\n",
       "      <td>13.695320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.018451</td>\n",
       "      <td>0.017839</td>\n",
       "      <td>3.427510</td>\n",
       "      <td>17.056019</td>\n",
       "      <td>0.018071</td>\n",
       "      <td>1.297002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.011417</td>\n",
       "      <td>0.011838</td>\n",
       "      <td>3.558575</td>\n",
       "      <td>24.988983</td>\n",
       "      <td>0.011499</td>\n",
       "      <td>2.863728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.013775</td>\n",
       "      <td>0.013993</td>\n",
       "      <td>1.557378</td>\n",
       "      <td>5.747412</td>\n",
       "      <td>0.014084</td>\n",
       "      <td>0.655415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.015862</td>\n",
       "      <td>0.017615</td>\n",
       "      <td>9.952833</td>\n",
       "      <td>16.000012</td>\n",
       "      <td>0.017413</td>\n",
       "      <td>1.149322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.016409</td>\n",
       "      <td>0.014808</td>\n",
       "      <td>10.814006</td>\n",
       "      <td>0.072640</td>\n",
       "      <td>0.015220</td>\n",
       "      <td>2.786417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.011505</td>\n",
       "      <td>0.013413</td>\n",
       "      <td>14.221793</td>\n",
       "      <td>10.317958</td>\n",
       "      <td>0.011609</td>\n",
       "      <td>13.446796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.015745</td>\n",
       "      <td>0.016822</td>\n",
       "      <td>6.405124</td>\n",
       "      <td>12.041567</td>\n",
       "      <td>0.014106</td>\n",
       "      <td>16.150436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.011877</td>\n",
       "      <td>0.013555</td>\n",
       "      <td>12.378038</td>\n",
       "      <td>9.159628</td>\n",
       "      <td>0.011895</td>\n",
       "      <td>12.247870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.007287</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>24.606606</td>\n",
       "      <td>153.024363</td>\n",
       "      <td>0.009264</td>\n",
       "      <td>58.407342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.018716</td>\n",
       "      <td>0.016688</td>\n",
       "      <td>12.149860</td>\n",
       "      <td>11.333348</td>\n",
       "      <td>0.018106</td>\n",
       "      <td>8.497906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.010808</td>\n",
       "      <td>0.008606</td>\n",
       "      <td>25.593174</td>\n",
       "      <td>71.938186</td>\n",
       "      <td>0.011149</td>\n",
       "      <td>29.548136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.015847</td>\n",
       "      <td>0.030172</td>\n",
       "      <td>47.478178</td>\n",
       "      <td>50.959357</td>\n",
       "      <td>0.015513</td>\n",
       "      <td>48.586719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.009876</td>\n",
       "      <td>0.007077</td>\n",
       "      <td>39.555051</td>\n",
       "      <td>109.089388</td>\n",
       "      <td>0.011352</td>\n",
       "      <td>60.416603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.015211</td>\n",
       "      <td>0.012871</td>\n",
       "      <td>18.180694</td>\n",
       "      <td>14.959334</td>\n",
       "      <td>0.014281</td>\n",
       "      <td>10.954862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.016749</td>\n",
       "      <td>0.018027</td>\n",
       "      <td>7.086393</td>\n",
       "      <td>17.916997</td>\n",
       "      <td>0.016492</td>\n",
       "      <td>8.515398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.020805</td>\n",
       "      <td>0.016886</td>\n",
       "      <td>23.208879</td>\n",
       "      <td>12.370381</td>\n",
       "      <td>0.020870</td>\n",
       "      <td>23.598837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.015236</td>\n",
       "      <td>0.016441</td>\n",
       "      <td>7.328915</td>\n",
       "      <td>10.000971</td>\n",
       "      <td>0.015959</td>\n",
       "      <td>2.934042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.017409</td>\n",
       "      <td>0.016190</td>\n",
       "      <td>7.525134</td>\n",
       "      <td>8.608334</td>\n",
       "      <td>0.017694</td>\n",
       "      <td>9.286254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    uber_pred    actual  percent_linear_regression_error  baseline_error  \\\n",
       "0    0.016814  0.017316                         2.898004       14.548791   \n",
       "1    0.013113  0.009590                        36.729357       54.289710   \n",
       "2    0.016005  0.015931                         0.460145        7.121967   \n",
       "3    0.016263  0.012799                        27.065443       15.611906   \n",
       "4    0.010821  0.009040                        19.693094       63.674769   \n",
       "5    0.014911  0.013052                        14.240990       13.365836   \n",
       "6    0.017691  0.019200                         7.858594       22.933616   \n",
       "7    0.014153  0.013798                         2.575454        7.237467   \n",
       "8    0.014036  0.012452                        12.720393       18.829254   \n",
       "9    0.012042  0.008398                        43.388628       76.186973   \n",
       "10   0.018081  0.015402                        17.400273        3.926842   \n",
       "11   0.014753  0.021525                        31.461188       31.258546   \n",
       "12   0.019897  0.016861                        18.001891       12.243914   \n",
       "13   0.018904  0.020776                         9.008975       28.778329   \n",
       "14   0.014005  0.012683                        10.420997       16.666648   \n",
       "15   0.008379  0.007595                        10.328212       94.823812   \n",
       "16   0.012731  0.011756                         8.291450       25.864816   \n",
       "17   0.018606  0.024159                        22.985883       38.752043   \n",
       "18   0.015621  0.014365                         8.749428        3.008114   \n",
       "19   0.013531  0.008507                        59.050650       73.929026   \n",
       "20   0.014561  0.015886                         8.338939        6.854488   \n",
       "21   0.010955  0.009150                        19.721378       61.707290   \n",
       "22   0.014310  0.009442                        51.555863       56.710991   \n",
       "23   0.015892  0.012948                        22.737536       14.276408   \n",
       "24   0.008164  0.007159                        14.047226      106.692034   \n",
       "25   0.013424  0.010737                        25.019972       37.807029   \n",
       "26   0.020209  0.024000                        15.797831       38.346892   \n",
       "27   0.008656  0.008526                         1.522467       73.544682   \n",
       "28   0.013419  0.010621                        26.345103       39.317053   \n",
       "29   0.017325  0.020681                        16.227356       28.453381   \n",
       "30   0.013959  0.013908                         0.363084        6.388601   \n",
       "31   0.012508  0.010425                        19.978382       41.934939   \n",
       "32   0.018451  0.017839                         3.427510       17.056019   \n",
       "33   0.011417  0.011838                         3.558575       24.988983   \n",
       "34   0.013775  0.013993                         1.557378        5.747412   \n",
       "35   0.015862  0.017615                         9.952833       16.000012   \n",
       "36   0.016409  0.014808                        10.814006        0.072640   \n",
       "37   0.011505  0.013413                        14.221793       10.317958   \n",
       "38   0.015745  0.016822                         6.405124       12.041567   \n",
       "39   0.011877  0.013555                        12.378038        9.159628   \n",
       "40   0.007287  0.005848                        24.606606      153.024363   \n",
       "41   0.018716  0.016688                        12.149860       11.333348   \n",
       "42   0.010808  0.008606                        25.593174       71.938186   \n",
       "43   0.015847  0.030172                        47.478178       50.959357   \n",
       "44   0.009876  0.007077                        39.555051      109.089388   \n",
       "45   0.015211  0.012871                        18.180694       14.959334   \n",
       "46   0.016749  0.018027                         7.086393       17.916997   \n",
       "47   0.020805  0.016886                        23.208879       12.370381   \n",
       "48   0.015236  0.016441                         7.328915       10.000971   \n",
       "49   0.017409  0.016190                         7.525134        8.608334   \n",
       "\n",
       "    uber_pred_rf  percent_random_forest_error  \n",
       "0       0.015533                    10.299190  \n",
       "1       0.013129                    36.898197  \n",
       "2       0.013178                    17.284054  \n",
       "3       0.014937                    16.706879  \n",
       "4       0.012361                    36.731897  \n",
       "5       0.014569                    11.621041  \n",
       "6       0.017877                     6.892631  \n",
       "7       0.012870                     6.729413  \n",
       "8       0.014705                    18.095251  \n",
       "9       0.010619                    26.438498  \n",
       "10      0.018293                    18.770946  \n",
       "11      0.014923                    30.670501  \n",
       "12      0.021997                    30.461449  \n",
       "13      0.018208                    12.361087  \n",
       "14      0.013812                     8.898630  \n",
       "15      0.010696                    40.832254  \n",
       "16      0.011988                     1.973511  \n",
       "17      0.017681                    26.812377  \n",
       "18      0.015625                     8.775644  \n",
       "19      0.013535                    59.098033  \n",
       "20      0.012490                    21.378187  \n",
       "21      0.011826                    29.241217  \n",
       "22      0.013178                    39.569094  \n",
       "23      0.014834                    14.567736  \n",
       "24      0.010541                    47.245069  \n",
       "25      0.012305                    14.600571  \n",
       "26      0.019291                    19.621025  \n",
       "27      0.010181                    19.402908  \n",
       "28      0.012226                    15.109210  \n",
       "29      0.016755                    18.982341  \n",
       "30      0.013040                     6.244065  \n",
       "31      0.011853                    13.695320  \n",
       "32      0.018071                     1.297002  \n",
       "33      0.011499                     2.863728  \n",
       "34      0.014084                     0.655415  \n",
       "35      0.017413                     1.149322  \n",
       "36      0.015220                     2.786417  \n",
       "37      0.011609                    13.446796  \n",
       "38      0.014106                    16.150436  \n",
       "39      0.011895                    12.247870  \n",
       "40      0.009264                    58.407342  \n",
       "41      0.018106                     8.497906  \n",
       "42      0.011149                    29.548136  \n",
       "43      0.015513                    48.586719  \n",
       "44      0.011352                    60.416603  \n",
       "45      0.014281                    10.954862  \n",
       "46      0.016492                     8.515398  \n",
       "47      0.020870                    23.598837  \n",
       "48      0.015959                     2.934042  \n",
       "49      0.017694                     9.286254  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['uber_pred_rf'] = random_forest_predictions                                   # Adding the random forest predictions to the output dataframe\n",
    "output['percent_random_forest_error'] = abs(output['actual']-output['uber_pred_rf'])*100/output['actual']                  # Calculating the percentage error between the actual and the random forest predicted values.\n",
    "output.head(n=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much difference is seen using this method, lets try something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Baseline Error:  27.554613385672802\n",
      "Mean Linear Regression Error:  18.707245355226576\n",
      "Mean Random Forest Error:  18.450691144126264\n"
     ]
    }
   ],
   "source": [
    "print ('Mean Baseline Error: ', output['baseline_error'].mean())\n",
    "print ('Mean Linear Regression Error: ', output['percent_linear_regression_error'].mean())\n",
    "print ('Mean Random Forest Error: ', output['percent_random_forest_error'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The root mean squared error is more sensitive than other measures to the occasional large error**: the squaring process gives disproportionate weight to very large errors. If an occasional large error is not a problem in your decision situation (e.g., if the true cost of an error is roughly proportional to the size of the error, not the square of the error), then the MAE or MAPE may be a more relevant criterion. In many cases these statistics will vary in unison--the model that is best on one of them will also be better on the others--but this may not be the case when the error distribution has outliers. If one model is best on one measure and another is best on another measure, they are probably pretty similar in terms of their average errors. In such cases you probably should give more weight to some of the other criteria for comparing models--e.g., simplicity, intuitive reasonableness, etc. \n",
    "\n",
    "[Read More: Mean Squared Error](https://people.duke.edu/~rnau/compare.htm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of linear regression:  1.3541549794823842e-05\n",
      "MSE of random forest:  1.314561782367674e-05\n",
      "RMSE of linear regression:  0.003679884481179245\n",
      "RMSE of random forest:  0.0036256885999319827\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt \n",
    "\n",
    "ms_regression = mean_squared_error(output['actual'], output['uber_pred'])\n",
    "ms_rf = mean_squared_error(output['actual'],output['uber_pred_rf'])\n",
    "\n",
    "print ('MSE of linear regression: ', ms_regression)\n",
    "print ('MSE of random forest: ', ms_rf)\n",
    "\n",
    "rms_regression = sqrt(mean_squared_error(output['actual'], output['uber_pred']))\n",
    "rms_rf = sqrt(mean_squared_error(output['actual'],output['uber_pred_rf']))\n",
    "\n",
    "print ('RMSE of linear regression: ', rms_regression)\n",
    "print ('RMSE of random forest: ', rms_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "param = {'max_depth':4, 'eta':1, 'silent':1, 'objective':'reg:linear', 'eval_metric': 'auc' }\n",
    "num_round = 5\n",
    "model = xgb.train(param, dtrain, num_round)\n",
    "xgboost_predictions = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uber_pred</th>\n",
       "      <th>actual</th>\n",
       "      <th>percent_linear_regression_error</th>\n",
       "      <th>baseline_error</th>\n",
       "      <th>uber_pred_rf</th>\n",
       "      <th>percent_random_forest_error</th>\n",
       "      <th>uber_pred_xgboost</th>\n",
       "      <th>percent_xgboost_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016814</td>\n",
       "      <td>0.017316</td>\n",
       "      <td>2.898004</td>\n",
       "      <td>14.548791</td>\n",
       "      <td>0.015533</td>\n",
       "      <td>10.299190</td>\n",
       "      <td>0.016412</td>\n",
       "      <td>5.222478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013113</td>\n",
       "      <td>0.009590</td>\n",
       "      <td>36.729357</td>\n",
       "      <td>54.289710</td>\n",
       "      <td>0.013129</td>\n",
       "      <td>36.898197</td>\n",
       "      <td>0.012034</td>\n",
       "      <td>25.478998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016005</td>\n",
       "      <td>0.015931</td>\n",
       "      <td>0.460145</td>\n",
       "      <td>7.121967</td>\n",
       "      <td>0.013178</td>\n",
       "      <td>17.284054</td>\n",
       "      <td>0.013866</td>\n",
       "      <td>12.963954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016263</td>\n",
       "      <td>0.012799</td>\n",
       "      <td>27.065443</td>\n",
       "      <td>15.611906</td>\n",
       "      <td>0.014937</td>\n",
       "      <td>16.706879</td>\n",
       "      <td>0.016412</td>\n",
       "      <td>28.230018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010821</td>\n",
       "      <td>0.009040</td>\n",
       "      <td>19.693094</td>\n",
       "      <td>63.674769</td>\n",
       "      <td>0.012361</td>\n",
       "      <td>36.731897</td>\n",
       "      <td>0.011512</td>\n",
       "      <td>27.345168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.014911</td>\n",
       "      <td>0.013052</td>\n",
       "      <td>14.240990</td>\n",
       "      <td>13.365836</td>\n",
       "      <td>0.014569</td>\n",
       "      <td>11.621041</td>\n",
       "      <td>0.013560</td>\n",
       "      <td>3.889981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.017691</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>7.858594</td>\n",
       "      <td>22.933616</td>\n",
       "      <td>0.017877</td>\n",
       "      <td>6.892631</td>\n",
       "      <td>0.018772</td>\n",
       "      <td>2.230532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.014153</td>\n",
       "      <td>0.013798</td>\n",
       "      <td>2.575454</td>\n",
       "      <td>7.237467</td>\n",
       "      <td>0.012870</td>\n",
       "      <td>6.729413</td>\n",
       "      <td>0.012650</td>\n",
       "      <td>8.318537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.014036</td>\n",
       "      <td>0.012452</td>\n",
       "      <td>12.720393</td>\n",
       "      <td>18.829254</td>\n",
       "      <td>0.014705</td>\n",
       "      <td>18.095251</td>\n",
       "      <td>0.013484</td>\n",
       "      <td>8.283314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.012042</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>43.388628</td>\n",
       "      <td>76.186973</td>\n",
       "      <td>0.010619</td>\n",
       "      <td>26.438498</td>\n",
       "      <td>0.009223</td>\n",
       "      <td>9.823300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.018081</td>\n",
       "      <td>0.015402</td>\n",
       "      <td>17.400273</td>\n",
       "      <td>3.926842</td>\n",
       "      <td>0.018293</td>\n",
       "      <td>18.770946</td>\n",
       "      <td>0.019474</td>\n",
       "      <td>26.439384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.014753</td>\n",
       "      <td>0.021525</td>\n",
       "      <td>31.461188</td>\n",
       "      <td>31.258546</td>\n",
       "      <td>0.014923</td>\n",
       "      <td>30.670501</td>\n",
       "      <td>0.016508</td>\n",
       "      <td>23.306410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.019897</td>\n",
       "      <td>0.016861</td>\n",
       "      <td>18.001891</td>\n",
       "      <td>12.243914</td>\n",
       "      <td>0.021997</td>\n",
       "      <td>30.461449</td>\n",
       "      <td>0.022354</td>\n",
       "      <td>32.576280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.018904</td>\n",
       "      <td>0.020776</td>\n",
       "      <td>9.008975</td>\n",
       "      <td>28.778329</td>\n",
       "      <td>0.018208</td>\n",
       "      <td>12.361087</td>\n",
       "      <td>0.017516</td>\n",
       "      <td>15.690718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.014005</td>\n",
       "      <td>0.012683</td>\n",
       "      <td>10.420997</td>\n",
       "      <td>16.666648</td>\n",
       "      <td>0.013812</td>\n",
       "      <td>8.898630</td>\n",
       "      <td>0.012034</td>\n",
       "      <td>5.118663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.008379</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>10.328212</td>\n",
       "      <td>94.823812</td>\n",
       "      <td>0.010696</td>\n",
       "      <td>40.832254</td>\n",
       "      <td>0.009814</td>\n",
       "      <td>29.223079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.012731</td>\n",
       "      <td>0.011756</td>\n",
       "      <td>8.291450</td>\n",
       "      <td>25.864816</td>\n",
       "      <td>0.011988</td>\n",
       "      <td>1.973511</td>\n",
       "      <td>0.011877</td>\n",
       "      <td>1.032788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.018606</td>\n",
       "      <td>0.024159</td>\n",
       "      <td>22.985883</td>\n",
       "      <td>38.752043</td>\n",
       "      <td>0.017681</td>\n",
       "      <td>26.812377</td>\n",
       "      <td>0.019002</td>\n",
       "      <td>21.346814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.015621</td>\n",
       "      <td>0.014365</td>\n",
       "      <td>8.749428</td>\n",
       "      <td>3.008114</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>8.775644</td>\n",
       "      <td>0.015327</td>\n",
       "      <td>6.700790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.013531</td>\n",
       "      <td>0.008507</td>\n",
       "      <td>59.050650</td>\n",
       "      <td>73.929026</td>\n",
       "      <td>0.013535</td>\n",
       "      <td>59.098033</td>\n",
       "      <td>0.010058</td>\n",
       "      <td>18.225303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.014561</td>\n",
       "      <td>0.015886</td>\n",
       "      <td>8.338939</td>\n",
       "      <td>6.854488</td>\n",
       "      <td>0.012490</td>\n",
       "      <td>21.378187</td>\n",
       "      <td>0.012130</td>\n",
       "      <td>23.642264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.010955</td>\n",
       "      <td>0.009150</td>\n",
       "      <td>19.721378</td>\n",
       "      <td>61.707290</td>\n",
       "      <td>0.011826</td>\n",
       "      <td>29.241217</td>\n",
       "      <td>0.011512</td>\n",
       "      <td>25.814395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.014310</td>\n",
       "      <td>0.009442</td>\n",
       "      <td>51.555863</td>\n",
       "      <td>56.710991</td>\n",
       "      <td>0.013178</td>\n",
       "      <td>39.569094</td>\n",
       "      <td>0.014106</td>\n",
       "      <td>49.393213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.015892</td>\n",
       "      <td>0.012948</td>\n",
       "      <td>22.737536</td>\n",
       "      <td>14.276408</td>\n",
       "      <td>0.014834</td>\n",
       "      <td>14.567736</td>\n",
       "      <td>0.015169</td>\n",
       "      <td>17.150163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.008164</td>\n",
       "      <td>0.007159</td>\n",
       "      <td>14.047226</td>\n",
       "      <td>106.692034</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>47.245069</td>\n",
       "      <td>0.009814</td>\n",
       "      <td>37.095053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.013424</td>\n",
       "      <td>0.010737</td>\n",
       "      <td>25.019972</td>\n",
       "      <td>37.807029</td>\n",
       "      <td>0.012305</td>\n",
       "      <td>14.600571</td>\n",
       "      <td>0.010629</td>\n",
       "      <td>1.011092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.020209</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>15.797831</td>\n",
       "      <td>38.346892</td>\n",
       "      <td>0.019291</td>\n",
       "      <td>19.621025</td>\n",
       "      <td>0.020422</td>\n",
       "      <td>14.908285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.008656</td>\n",
       "      <td>0.008526</td>\n",
       "      <td>1.522467</td>\n",
       "      <td>73.544682</td>\n",
       "      <td>0.010181</td>\n",
       "      <td>19.402908</td>\n",
       "      <td>0.009572</td>\n",
       "      <td>12.262027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.013419</td>\n",
       "      <td>0.010621</td>\n",
       "      <td>26.345103</td>\n",
       "      <td>39.317053</td>\n",
       "      <td>0.012226</td>\n",
       "      <td>15.109210</td>\n",
       "      <td>0.011877</td>\n",
       "      <td>11.831016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.017325</td>\n",
       "      <td>0.020681</td>\n",
       "      <td>16.227356</td>\n",
       "      <td>28.453381</td>\n",
       "      <td>0.016755</td>\n",
       "      <td>18.982341</td>\n",
       "      <td>0.015327</td>\n",
       "      <td>25.888550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.013959</td>\n",
       "      <td>0.013908</td>\n",
       "      <td>0.363084</td>\n",
       "      <td>6.388601</td>\n",
       "      <td>0.013040</td>\n",
       "      <td>6.244065</td>\n",
       "      <td>0.011904</td>\n",
       "      <td>14.408518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.012508</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>19.978382</td>\n",
       "      <td>41.934939</td>\n",
       "      <td>0.011853</td>\n",
       "      <td>13.695320</td>\n",
       "      <td>0.011877</td>\n",
       "      <td>13.932416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.018451</td>\n",
       "      <td>0.017839</td>\n",
       "      <td>3.427510</td>\n",
       "      <td>17.056019</td>\n",
       "      <td>0.018071</td>\n",
       "      <td>1.297002</td>\n",
       "      <td>0.018171</td>\n",
       "      <td>1.856949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.011417</td>\n",
       "      <td>0.011838</td>\n",
       "      <td>3.558575</td>\n",
       "      <td>24.988983</td>\n",
       "      <td>0.011499</td>\n",
       "      <td>2.863728</td>\n",
       "      <td>0.010629</td>\n",
       "      <td>10.218491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.013775</td>\n",
       "      <td>0.013993</td>\n",
       "      <td>1.557378</td>\n",
       "      <td>5.747412</td>\n",
       "      <td>0.014084</td>\n",
       "      <td>0.655415</td>\n",
       "      <td>0.013484</td>\n",
       "      <td>3.637531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.015862</td>\n",
       "      <td>0.017615</td>\n",
       "      <td>9.952833</td>\n",
       "      <td>16.000012</td>\n",
       "      <td>0.017413</td>\n",
       "      <td>1.149322</td>\n",
       "      <td>0.018618</td>\n",
       "      <td>5.693900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.016409</td>\n",
       "      <td>0.014808</td>\n",
       "      <td>10.814006</td>\n",
       "      <td>0.072640</td>\n",
       "      <td>0.015220</td>\n",
       "      <td>2.786417</td>\n",
       "      <td>0.015865</td>\n",
       "      <td>7.140416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.011505</td>\n",
       "      <td>0.013413</td>\n",
       "      <td>14.221793</td>\n",
       "      <td>10.317958</td>\n",
       "      <td>0.011609</td>\n",
       "      <td>13.446796</td>\n",
       "      <td>0.011255</td>\n",
       "      <td>16.085976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.015745</td>\n",
       "      <td>0.016822</td>\n",
       "      <td>6.405124</td>\n",
       "      <td>12.041567</td>\n",
       "      <td>0.014106</td>\n",
       "      <td>16.150436</td>\n",
       "      <td>0.014106</td>\n",
       "      <td>16.148875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.011877</td>\n",
       "      <td>0.013555</td>\n",
       "      <td>12.378038</td>\n",
       "      <td>9.159628</td>\n",
       "      <td>0.011895</td>\n",
       "      <td>12.247870</td>\n",
       "      <td>0.011161</td>\n",
       "      <td>17.664462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.007287</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>24.606606</td>\n",
       "      <td>153.024363</td>\n",
       "      <td>0.009264</td>\n",
       "      <td>58.407342</td>\n",
       "      <td>0.009572</td>\n",
       "      <td>63.675588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.018716</td>\n",
       "      <td>0.016688</td>\n",
       "      <td>12.149860</td>\n",
       "      <td>11.333348</td>\n",
       "      <td>0.018106</td>\n",
       "      <td>8.497906</td>\n",
       "      <td>0.019474</td>\n",
       "      <td>16.691874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.010808</td>\n",
       "      <td>0.008606</td>\n",
       "      <td>25.593174</td>\n",
       "      <td>71.938186</td>\n",
       "      <td>0.011149</td>\n",
       "      <td>29.548136</td>\n",
       "      <td>0.011161</td>\n",
       "      <td>29.687351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.015847</td>\n",
       "      <td>0.030172</td>\n",
       "      <td>47.478178</td>\n",
       "      <td>50.959357</td>\n",
       "      <td>0.015513</td>\n",
       "      <td>48.586719</td>\n",
       "      <td>0.016412</td>\n",
       "      <td>45.606964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.009876</td>\n",
       "      <td>0.007077</td>\n",
       "      <td>39.555051</td>\n",
       "      <td>109.089388</td>\n",
       "      <td>0.011352</td>\n",
       "      <td>60.416603</td>\n",
       "      <td>0.011161</td>\n",
       "      <td>57.709288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.015211</td>\n",
       "      <td>0.012871</td>\n",
       "      <td>18.180694</td>\n",
       "      <td>14.959334</td>\n",
       "      <td>0.014281</td>\n",
       "      <td>10.954862</td>\n",
       "      <td>0.013560</td>\n",
       "      <td>5.350285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.016749</td>\n",
       "      <td>0.018027</td>\n",
       "      <td>7.086393</td>\n",
       "      <td>17.916997</td>\n",
       "      <td>0.016492</td>\n",
       "      <td>8.515398</td>\n",
       "      <td>0.016288</td>\n",
       "      <td>9.644558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.020805</td>\n",
       "      <td>0.016886</td>\n",
       "      <td>23.208879</td>\n",
       "      <td>12.370381</td>\n",
       "      <td>0.020870</td>\n",
       "      <td>23.598837</td>\n",
       "      <td>0.020664</td>\n",
       "      <td>22.376489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.015236</td>\n",
       "      <td>0.016441</td>\n",
       "      <td>7.328915</td>\n",
       "      <td>10.000971</td>\n",
       "      <td>0.015959</td>\n",
       "      <td>2.934042</td>\n",
       "      <td>0.014106</td>\n",
       "      <td>14.203566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.017409</td>\n",
       "      <td>0.016190</td>\n",
       "      <td>7.525134</td>\n",
       "      <td>8.608334</td>\n",
       "      <td>0.017694</td>\n",
       "      <td>9.286254</td>\n",
       "      <td>0.016412</td>\n",
       "      <td>1.366334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    uber_pred    actual  percent_linear_regression_error  baseline_error  \\\n",
       "0    0.016814  0.017316                         2.898004       14.548791   \n",
       "1    0.013113  0.009590                        36.729357       54.289710   \n",
       "2    0.016005  0.015931                         0.460145        7.121967   \n",
       "3    0.016263  0.012799                        27.065443       15.611906   \n",
       "4    0.010821  0.009040                        19.693094       63.674769   \n",
       "5    0.014911  0.013052                        14.240990       13.365836   \n",
       "6    0.017691  0.019200                         7.858594       22.933616   \n",
       "7    0.014153  0.013798                         2.575454        7.237467   \n",
       "8    0.014036  0.012452                        12.720393       18.829254   \n",
       "9    0.012042  0.008398                        43.388628       76.186973   \n",
       "10   0.018081  0.015402                        17.400273        3.926842   \n",
       "11   0.014753  0.021525                        31.461188       31.258546   \n",
       "12   0.019897  0.016861                        18.001891       12.243914   \n",
       "13   0.018904  0.020776                         9.008975       28.778329   \n",
       "14   0.014005  0.012683                        10.420997       16.666648   \n",
       "15   0.008379  0.007595                        10.328212       94.823812   \n",
       "16   0.012731  0.011756                         8.291450       25.864816   \n",
       "17   0.018606  0.024159                        22.985883       38.752043   \n",
       "18   0.015621  0.014365                         8.749428        3.008114   \n",
       "19   0.013531  0.008507                        59.050650       73.929026   \n",
       "20   0.014561  0.015886                         8.338939        6.854488   \n",
       "21   0.010955  0.009150                        19.721378       61.707290   \n",
       "22   0.014310  0.009442                        51.555863       56.710991   \n",
       "23   0.015892  0.012948                        22.737536       14.276408   \n",
       "24   0.008164  0.007159                        14.047226      106.692034   \n",
       "25   0.013424  0.010737                        25.019972       37.807029   \n",
       "26   0.020209  0.024000                        15.797831       38.346892   \n",
       "27   0.008656  0.008526                         1.522467       73.544682   \n",
       "28   0.013419  0.010621                        26.345103       39.317053   \n",
       "29   0.017325  0.020681                        16.227356       28.453381   \n",
       "30   0.013959  0.013908                         0.363084        6.388601   \n",
       "31   0.012508  0.010425                        19.978382       41.934939   \n",
       "32   0.018451  0.017839                         3.427510       17.056019   \n",
       "33   0.011417  0.011838                         3.558575       24.988983   \n",
       "34   0.013775  0.013993                         1.557378        5.747412   \n",
       "35   0.015862  0.017615                         9.952833       16.000012   \n",
       "36   0.016409  0.014808                        10.814006        0.072640   \n",
       "37   0.011505  0.013413                        14.221793       10.317958   \n",
       "38   0.015745  0.016822                         6.405124       12.041567   \n",
       "39   0.011877  0.013555                        12.378038        9.159628   \n",
       "40   0.007287  0.005848                        24.606606      153.024363   \n",
       "41   0.018716  0.016688                        12.149860       11.333348   \n",
       "42   0.010808  0.008606                        25.593174       71.938186   \n",
       "43   0.015847  0.030172                        47.478178       50.959357   \n",
       "44   0.009876  0.007077                        39.555051      109.089388   \n",
       "45   0.015211  0.012871                        18.180694       14.959334   \n",
       "46   0.016749  0.018027                         7.086393       17.916997   \n",
       "47   0.020805  0.016886                        23.208879       12.370381   \n",
       "48   0.015236  0.016441                         7.328915       10.000971   \n",
       "49   0.017409  0.016190                         7.525134        8.608334   \n",
       "\n",
       "    uber_pred_rf  percent_random_forest_error  uber_pred_xgboost  \\\n",
       "0       0.015533                    10.299190           0.016412   \n",
       "1       0.013129                    36.898197           0.012034   \n",
       "2       0.013178                    17.284054           0.013866   \n",
       "3       0.014937                    16.706879           0.016412   \n",
       "4       0.012361                    36.731897           0.011512   \n",
       "5       0.014569                    11.621041           0.013560   \n",
       "6       0.017877                     6.892631           0.018772   \n",
       "7       0.012870                     6.729413           0.012650   \n",
       "8       0.014705                    18.095251           0.013484   \n",
       "9       0.010619                    26.438498           0.009223   \n",
       "10      0.018293                    18.770946           0.019474   \n",
       "11      0.014923                    30.670501           0.016508   \n",
       "12      0.021997                    30.461449           0.022354   \n",
       "13      0.018208                    12.361087           0.017516   \n",
       "14      0.013812                     8.898630           0.012034   \n",
       "15      0.010696                    40.832254           0.009814   \n",
       "16      0.011988                     1.973511           0.011877   \n",
       "17      0.017681                    26.812377           0.019002   \n",
       "18      0.015625                     8.775644           0.015327   \n",
       "19      0.013535                    59.098033           0.010058   \n",
       "20      0.012490                    21.378187           0.012130   \n",
       "21      0.011826                    29.241217           0.011512   \n",
       "22      0.013178                    39.569094           0.014106   \n",
       "23      0.014834                    14.567736           0.015169   \n",
       "24      0.010541                    47.245069           0.009814   \n",
       "25      0.012305                    14.600571           0.010629   \n",
       "26      0.019291                    19.621025           0.020422   \n",
       "27      0.010181                    19.402908           0.009572   \n",
       "28      0.012226                    15.109210           0.011877   \n",
       "29      0.016755                    18.982341           0.015327   \n",
       "30      0.013040                     6.244065           0.011904   \n",
       "31      0.011853                    13.695320           0.011877   \n",
       "32      0.018071                     1.297002           0.018171   \n",
       "33      0.011499                     2.863728           0.010629   \n",
       "34      0.014084                     0.655415           0.013484   \n",
       "35      0.017413                     1.149322           0.018618   \n",
       "36      0.015220                     2.786417           0.015865   \n",
       "37      0.011609                    13.446796           0.011255   \n",
       "38      0.014106                    16.150436           0.014106   \n",
       "39      0.011895                    12.247870           0.011161   \n",
       "40      0.009264                    58.407342           0.009572   \n",
       "41      0.018106                     8.497906           0.019474   \n",
       "42      0.011149                    29.548136           0.011161   \n",
       "43      0.015513                    48.586719           0.016412   \n",
       "44      0.011352                    60.416603           0.011161   \n",
       "45      0.014281                    10.954862           0.013560   \n",
       "46      0.016492                     8.515398           0.016288   \n",
       "47      0.020870                    23.598837           0.020664   \n",
       "48      0.015959                     2.934042           0.014106   \n",
       "49      0.017694                     9.286254           0.016412   \n",
       "\n",
       "    percent_xgboost_error  \n",
       "0                5.222478  \n",
       "1               25.478998  \n",
       "2               12.963954  \n",
       "3               28.230018  \n",
       "4               27.345168  \n",
       "5                3.889981  \n",
       "6                2.230532  \n",
       "7                8.318537  \n",
       "8                8.283314  \n",
       "9                9.823300  \n",
       "10              26.439384  \n",
       "11              23.306410  \n",
       "12              32.576280  \n",
       "13              15.690718  \n",
       "14               5.118663  \n",
       "15              29.223079  \n",
       "16               1.032788  \n",
       "17              21.346814  \n",
       "18               6.700790  \n",
       "19              18.225303  \n",
       "20              23.642264  \n",
       "21              25.814395  \n",
       "22              49.393213  \n",
       "23              17.150163  \n",
       "24              37.095053  \n",
       "25               1.011092  \n",
       "26              14.908285  \n",
       "27              12.262027  \n",
       "28              11.831016  \n",
       "29              25.888550  \n",
       "30              14.408518  \n",
       "31              13.932416  \n",
       "32               1.856949  \n",
       "33              10.218491  \n",
       "34               3.637531  \n",
       "35               5.693900  \n",
       "36               7.140416  \n",
       "37              16.085976  \n",
       "38              16.148875  \n",
       "39              17.664462  \n",
       "40              63.675588  \n",
       "41              16.691874  \n",
       "42              29.687351  \n",
       "43              45.606964  \n",
       "44              57.709288  \n",
       "45               5.350285  \n",
       "46               9.644558  \n",
       "47              22.376489  \n",
       "48              14.203566  \n",
       "49               1.366334  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['uber_pred_xgboost'] = xgboost_predictions\n",
    "output['percent_xgboost_error'] = abs(output['actual']-output['uber_pred_xgboost'])*100/output['actual']\n",
    "output.head(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Baseline Error:  27.554613385672802\n",
      "Mean Linear Regression Error:  18.707245355226576\n",
      "Mean Random Forest Error:  18.450691144126264\n",
      "Mean XGBoost Error:  18.41060495973445\n"
     ]
    }
   ],
   "source": [
    "print ('Mean Baseline Error: ', output['baseline_error'].mean())\n",
    "print ('Mean Linear Regression Error: ', output['percent_linear_regression_error'].mean())\n",
    "print ('Mean Random Forest Error: ', output['percent_random_forest_error'].mean())\n",
    "print ('Mean XGBoost Error: ', output['percent_xgboost_error'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows us that even with other boosting algorithms we are unable to get the desired results. There is the possibility that the features we are using are not enough for predicting our label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] http://www.stat.yale.edu/Courses/1997-98/101/linreg.htm\n",
    "\n",
    "[2] https://pythonprogramming.net/machine-learning-tutorial-python-introduction/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The content of this project itself is licensed under the Creative Commons Attribution 3.0 license, and the underlying source code used to format and display that content is licensed under the [MIT License](https://github.com/rahilshah10/IS/blob/master/LICENSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
